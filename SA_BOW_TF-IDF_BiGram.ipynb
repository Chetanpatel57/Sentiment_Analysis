{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np     # import numpy as np                                  #for large and multi-dimensional arrays\n",
    "import pandas as pd                                 #for data manipulation and analysis\n",
    "import nltk                                         #Natural language processing tool-kit\n",
    "\n",
    "from nltk.corpus import stopwords                   #Stopwords corpus\n",
    "from nltk.stem import PorterStemmer                 # Stemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer          #For Bag of words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer          #For TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>mr costner drag movi far longer necessari asi...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>exampl major action film generic bore there r...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>first hate moron rapper couldnt act gun press...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>even beatl could write song everyon like alth...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>test</td>\n",
       "      <td>brass pictur movi fit word realli somewhat br...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  type  \\\n",
       "0           0             0  test   \n",
       "1           1             1  test   \n",
       "2           2             2  test   \n",
       "3           3             3  test   \n",
       "4           4             4  test   \n",
       "\n",
       "                                              review label  \n",
       "0   mr costner drag movi far longer necessari asi...   neg  \n",
       "1   exampl major action film generic bore there r...   neg  \n",
       "2   first hate moron rapper couldnt act gun press...   neg  \n",
       "3   even beatl could write song everyon like alth...   neg  \n",
       "4   brass pictur movi fit word realli somewhat br...   neg  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb = pd.read_csv(\"out1.csv\",delimiter = ',',encoding = \"ISO-8859-1\")\n",
    "imdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_X = imdb['review']\n",
    "final_y = imdb['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk                                         #Natural language processing tool-kit\n",
    "\n",
    "\"\"\"from nltk.corpus import stopwords                   #Stopwords corpus\n",
    "from nltk.stem import PorterStemmer                 # Stemmer\n",
    "\"\"\"\n",
    "from sklearn.feature_extraction.text import CountVectorizer          #For Bag of words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " exampl major action film generic bore there realli noth worth watch complet wast barely-tap talent ice-t ice cube whove proven mani time capabl act act well dont bother one go see new jack citi ricochet watch new york undercov ice-t boyz n hood higher learn friday ice cube see real deal ice-t horribl clich dialogu alon make film grate teeth im still wonder heck bill paxton film heck alway play exact charact alien onward everi film ive seen bill paxton play exact irrit charact least alien charact die made somewhat gratifi overal second-r action trash countless better film see realli want see one watch judgement night practic carbon copi better act better script thing made worth watch decent hand camera - cinematographi almost refresh come close make horribl film - quit 4 10\n"
     ]
    }
   ],
   "source": [
    "print(final_X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"sent = []\\nfor row in final_X:\\n    sequ = ''\\n    for word in row:\\n        sequ = sequ + '' + word\\n    sent.append(sequ)\\nfinal_X = sent\\nprint(final_X[1])\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"sent = []\n",
    "for row in final_X:\n",
    "    sequ = ''\n",
    "    for word in row:\n",
    "        sequ = sequ + '' + word\n",
    "    sent.append(sequ)\n",
    "final_X = sent\n",
    "print(final_X[1])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4)\t1\n",
      "  (0, 7085)\t1\n",
      "  (0, 1785)\t1\n",
      "  (0, 7260)\t1\n",
      "  (0, 424)\t1\n",
      "  (0, 1714)\t1\n",
      "  (0, 1379)\t1\n",
      "  (0, 4060)\t1\n",
      "  (0, 2351)\t1\n",
      "  (0, 8921)\t1\n",
      "  (0, 7769)\t1\n",
      "  (0, 2038)\t1\n",
      "  (0, 1433)\t1\n",
      "  (0, 6855)\t1\n",
      "  (0, 6120)\t1\n",
      "  (0, 4886)\t1\n",
      "  (0, 9641)\t1\n",
      "  (0, 2089)\t1\n",
      "  (0, 9124)\t1\n",
      "  (0, 7793)\t1\n",
      "  (0, 6388)\t1\n",
      "  (0, 8242)\t1\n",
      "  (0, 5440)\t2\n",
      "  (0, 2528)\t1\n",
      "  (0, 5156)\t1\n",
      "  :\t:\n",
      "  (0, 5494)\t1\n",
      "  (0, 6997)\t1\n",
      "  (0, 9780)\t1\n",
      "  (0, 2199)\t2\n",
      "  (0, 4438)\t5\n",
      "  (0, 8761)\t1\n",
      "  (0, 8774)\t1\n",
      "  (0, 9664)\t1\n",
      "  (0, 1914)\t1\n",
      "  (0, 9667)\t4\n",
      "  (0, 9879)\t2\n",
      "  (0, 6186)\t1\n",
      "  (0, 8901)\t1\n",
      "  (0, 1141)\t1\n",
      "  (0, 3720)\t1\n",
      "  (0, 3380)\t6\n",
      "  (0, 271)\t2\n",
      "  (0, 5467)\t1\n",
      "  (0, 3150)\t1\n",
      "  (0, 9719)\t1\n",
      "  (0, 982)\t3\n",
      "  (0, 1872)\t1\n",
      "  (0, 7195)\t2\n",
      "  (0, 8993)\t1\n",
      "  (0, 1586)\t3\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer(max_features=10000)\n",
    "bow_data = count_vect.fit_transform(final_X)\n",
    "print(bow_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , x_val, y_train , y_val = train_test_split(bow_data,final_y,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.84      0.84      0.84      4961\n",
      "        pos       0.85      0.85      0.85      5039\n",
      "\n",
      "avg / total       0.84      0.84      0.84     10000\n",
      "\n",
      "0.8444\n"
     ]
    }
   ],
   "source": [
    "svm = LinearSVC()\n",
    "svm.fit(x_train,y_train)\n",
    "print(classification_report( svm.predict(x_val) , y_val))\n",
    "print(accuracy_score( svm.predict(x_val) , y_val ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.86      0.84      0.85      5057\n",
      "        pos       0.84      0.85      0.85      4943\n",
      "\n",
      "avg / total       0.85      0.85      0.85     10000\n",
      "\n",
      "0.8466\n"
     ]
    }
   ],
   "source": [
    "nb=MultinomialNB()\n",
    "nb.fit(x_train,y_train)\n",
    "print(classification_report( nb.predict(x_val) , y_val))\n",
    "print(accuracy_score( nb.predict(x_val) , y_val ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.87      0.87      0.87      4937\n",
      "        pos       0.88      0.87      0.87      5063\n",
      "\n",
      "avg / total       0.87      0.87      0.87     10000\n",
      "\n",
      "0.8736\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "print(classification_report( lr.predict(x_val) , y_val))\n",
    "print(accuracy_score( lr.predict(x_val) , y_val ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.87      0.85      0.86      4959\n",
      "        pos       0.86      0.88      0.87      5041\n",
      "\n",
      "avg / total       0.87      0.87      0.87     10000\n",
      "\n",
      "0.8655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(15, 15), learning_rate='constant',\n",
    "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='sgd', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=False, warm_start=False)\n",
    "mlp.fit(x_train,y_train)\n",
    "predictions = mlp.predict(x_val)\n",
    "print(classification_report(y_val,predictions))\n",
    "print(accuracy_score( predictions, y_val ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [ ('svm',svm) , ('nb' , nb), ('mlp' , mlp) ]\n",
    "clf = VotingClassifier(estimators , voting='hard')\n",
    "clf.fit(x_train,y_train)\n",
    "print(classification_report( clf.predict(x_val) , y_val))\n",
    "print(accuracy_score( clf.predict(x_val) , y_val ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1931666)\t1\n",
      "  (0, 907325)\t1\n",
      "  (0, 1167768)\t1\n",
      "  (0, 1480336)\t1\n",
      "  (0, 458538)\t1\n",
      "  (0, 475180)\t1\n",
      "  (0, 1979726)\t1\n",
      "  (0, 94326)\t1\n",
      "  (0, 440214)\t1\n",
      "  (0, 357913)\t1\n",
      "  (0, 1094597)\t1\n",
      "  (0, 609734)\t1\n",
      "  (0, 2642086)\t1\n",
      "  (0, 1471155)\t1\n",
      "  (0, 2439828)\t1\n",
      "  (0, 2113675)\t1\n",
      "  (0, 260467)\t1\n",
      "  (0, 44935)\t1\n",
      "  (0, 258557)\t1\n",
      "  (0, 528526)\t1\n",
      "  (0, 369997)\t1\n",
      "  (0, 1867965)\t1\n",
      "  (0, 1664904)\t1\n",
      "  (0, 1304283)\t1\n",
      "  (0, 2643188)\t1\n",
      "  :\t:\n",
      "  (0, 1908852)\t1\n",
      "  (0, 2680525)\t1\n",
      "  (0, 571868)\t2\n",
      "  (0, 1194739)\t5\n",
      "  (0, 2393211)\t1\n",
      "  (0, 2398377)\t1\n",
      "  (0, 218738)\t1\n",
      "  (0, 2639983)\t1\n",
      "  (0, 492522)\t1\n",
      "  (0, 2640999)\t4\n",
      "  (0, 2720966)\t2\n",
      "  (0, 1678966)\t1\n",
      "  (0, 2432546)\t1\n",
      "  (0, 299188)\t1\n",
      "  (0, 1004665)\t1\n",
      "  (0, 901230)\t6\n",
      "  (0, 48052)\t2\n",
      "  (0, 1476974)\t1\n",
      "  (0, 820682)\t1\n",
      "  (0, 2660510)\t1\n",
      "  (0, 258493)\t3\n",
      "  (0, 474664)\t1\n",
      "  (0, 1962160)\t2\n",
      "  (0, 2464469)\t1\n",
      "  (0, 405734)\t3\n"
     ]
    }
   ],
   "source": [
    "final_B_X = final_X\n",
    "count_vect = CountVectorizer(ngram_range=(1,2))\n",
    "Bigram_data = count_vect.fit_transform(final_B_X)\n",
    "print(Bigram_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , x_val, y_train , y_val = train_test_split(Bigram_data,final_y,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.89      0.90      0.89      4864\n",
      "        pos       0.90      0.89      0.90      5136\n",
      "\n",
      "avg / total       0.90      0.90      0.90     10000\n",
      "\n",
      "0.8969\n"
     ]
    }
   ],
   "source": [
    "svm = LinearSVC()\n",
    "svm.fit(x_train,y_train)\n",
    "print(classification_report( svm.predict(x_val) , y_val))\n",
    "print(accuracy_score( svm.predict(x_val) , y_val ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.90      0.86      0.88      5147\n",
      "        pos       0.86      0.90      0.88      4853\n",
      "\n",
      "avg / total       0.88      0.88      0.88     10000\n",
      "\n",
      "0.8804\n"
     ]
    }
   ],
   "source": [
    "nb=MultinomialNB()\n",
    "nb.fit(x_train,y_train)\n",
    "print(classification_report( nb.predict(x_val) , y_val))\n",
    "print(accuracy_score( nb.predict(x_val) , y_val ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.89      0.90      0.90      4865\n",
      "        pos       0.91      0.90      0.90      5135\n",
      "\n",
      "avg / total       0.90      0.90      0.90     10000\n",
      "\n",
      "0.8994\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "print(classification_report( lr.predict(x_val) , y_val))\n",
    "print(accuracy_score( lr.predict(x_val) , y_val ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.90      0.89      0.90      4925\n",
      "        pos       0.89      0.91      0.90      5075\n",
      "\n",
      "avg / total       0.90      0.90      0.90     10000\n",
      "\n",
      "0.8979\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(15, 15), learning_rate='constant',\n",
    "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='sgd', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=False, warm_start=False)\n",
    "mlp.fit(x_train,y_train)\n",
    "predictions = mlp.predict(x_val)\n",
    "print(classification_report(y_val,predictions))\n",
    "print(accuracy_score( predictions, y_val ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 800)\t0.10979472885453861\n",
      "  (0, 4515)\t0.03302357557328847\n",
      "  (0, 3594)\t0.07623363403125137\n",
      "  (0, 942)\t0.04460385637394587\n",
      "  (0, 508)\t0.13941128288807522\n",
      "  (0, 4859)\t0.03788211931770136\n",
      "  (0, 1608)\t0.06874926093391821\n",
      "  (0, 2751)\t0.07231707818065877\n",
      "  (0, 142)\t0.11459830027566197\n",
      "  (0, 1743)\t0.15766312574199437\n",
      "  (0, 1921)\t0.11092625367403239\n",
      "  (0, 588)\t0.06021079829827451\n",
      "  (0, 4469)\t0.05809271452660225\n",
      "  (0, 3085)\t0.05185574139918607\n",
      "  (0, 4947)\t0.11958830663956337\n",
      "  (0, 4833)\t0.1386876684447635\n",
      "  (0, 970)\t0.056641009498929085\n",
      "  (0, 4832)\t0.06188969038317357\n",
      "  (0, 4404)\t0.11016744342718471\n",
      "  (0, 4398)\t0.06581583432498035\n",
      "  (0, 2255)\t0.49107237281819943\n",
      "  (0, 1130)\t0.2506524871721206\n",
      "  (0, 2762)\t0.04488793712549962\n",
      "  (0, 730)\t0.09598386683633552\n",
      "  (0, 140)\t0.11960831571514541\n",
      "  :\t:\n",
      "  (0, 3905)\t0.04400228034600453\n",
      "  (0, 2406)\t0.09179354608590025\n",
      "  (0, 2606)\t0.056023213547448464\n",
      "  (0, 1294)\t0.06443212705834517\n",
      "  (0, 2739)\t0.08331853285026845\n",
      "  (0, 4117)\t0.07575965071613874\n",
      "  (0, 3186)\t0.06823545124579615\n",
      "  (0, 3893)\t0.06066317148336661\n",
      "  (0, 4581)\t0.08592927473694878\n",
      "  (0, 1070)\t0.10951185802592514\n",
      "  (0, 4816)\t0.04502143455148687\n",
      "  (0, 3052)\t0.06262490049533559\n",
      "  (0, 3398)\t0.0886568479514205\n",
      "  (0, 1047)\t0.07970106103159318\n",
      "  (0, 3883)\t0.05579430980861237\n",
      "  (0, 4480)\t0.04193015624112643\n",
      "  (0, 1203)\t0.07296159174617356\n",
      "  (0, 2075)\t0.06226735293108509\n",
      "  (0, 710)\t0.06537559790963061\n",
      "  (0, 867)\t0.07465786440243076\n",
      "  (0, 223)\t0.05608498673536294\n",
      "  (0, 3626)\t0.09870496608982555\n",
      "  (0, 904)\t0.06583871541276508\n",
      "  (0, 3536)\t0.0537117515506946\n",
      "  (0, 2)\t0.051970900415071415\n"
     ]
    }
   ],
   "source": [
    "final_tf = final_X\n",
    "tf_idf = TfidfVectorizer(max_features=5000)\n",
    "tf_data = tf_idf.fit_transform(final_tf)\n",
    "print(tf_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , x_val, y_train , y_val = train_test_split(tf_data,final_y,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.88      0.88      0.88      4948\n",
      "        pos       0.88      0.88      0.88      5052\n",
      "\n",
      "avg / total       0.88      0.88      0.88     10000\n",
      "\n",
      "0.8819\n"
     ]
    }
   ],
   "source": [
    "svm = LinearSVC()\n",
    "svm.fit(x_train,y_train)\n",
    "print(classification_report( svm.predict(x_val) , y_val))\n",
    "print(accuracy_score( svm.predict(x_val) , y_val ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.84      0.85      0.85      4947\n",
      "        pos       0.85      0.85      0.85      5053\n",
      "\n",
      "avg / total       0.85      0.85      0.85     10000\n",
      "\n",
      "0.848\n"
     ]
    }
   ],
   "source": [
    "nb=MultinomialNB()\n",
    "nb.fit(x_train,y_train)\n",
    "print(classification_report( nb.predict(x_val) , y_val))\n",
    "print(accuracy_score( nb.predict(x_val) , y_val ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.88      0.89      0.89      4887\n",
      "        pos       0.90      0.88      0.89      5113\n",
      "\n",
      "avg / total       0.89      0.89      0.89     10000\n",
      "\n",
      "0.8884\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "print(classification_report( lr.predict(x_val) , y_val))\n",
    "print(accuracy_score( lr.predict(x_val) , y_val ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.88      0.88      0.88      4969\n",
      "        pos       0.88      0.89      0.88      5031\n",
      "\n",
      "avg / total       0.88      0.88      0.88     10000\n",
      "\n",
      "0.881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(15, 15), learning_rate='constant',\n",
    "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='sgd', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=False, warm_start=False)\n",
    "mlp.fit(x_train,y_train)\n",
    "predictions = mlp.predict(x_val)\n",
    "print(classification_report(y_val,predictions))\n",
    "print(accuracy_score( predictions, y_val ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
